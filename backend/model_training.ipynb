{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   itching  skin_rash  nodal_skin_eruptions  continuous_sneezing  shivering  \\\n",
      "0        1          1                     1                    0          0   \n",
      "1        0          1                     1                    0          0   \n",
      "2        1          0                     1                    0          0   \n",
      "3        1          1                     0                    0          0   \n",
      "4        1          1                     1                    0          0   \n",
      "\n",
      "   chills  joint_pain  stomach_pain  acidity  ulcers_on_tongue  ...  \\\n",
      "0       0           0             0        0                 0  ...   \n",
      "1       0           0             0        0                 0  ...   \n",
      "2       0           0             0        0                 0  ...   \n",
      "3       0           0             0        0                 0  ...   \n",
      "4       0           0             0        0                 0  ...   \n",
      "\n",
      "   blackheads  scurring  skin_peeling  silver_like_dusting  \\\n",
      "0           0         0             0                    0   \n",
      "1           0         0             0                    0   \n",
      "2           0         0             0                    0   \n",
      "3           0         0             0                    0   \n",
      "4           0         0             0                    0   \n",
      "\n",
      "   small_dents_in_nails  inflammatory_nails  blister  red_sore_around_nose  \\\n",
      "0                     0                   0        0                     0   \n",
      "1                     0                   0        0                     0   \n",
      "2                     0                   0        0                     0   \n",
      "3                     0                   0        0                     0   \n",
      "4                     0                   0        0                     0   \n",
      "\n",
      "   yellow_crust_ooze         prognosis  \n",
      "0                  0  Fungal infection  \n",
      "1                  0  Fungal infection  \n",
      "2                  0  Fungal infection  \n",
      "3                  0  Fungal infection  \n",
      "4                  0  Fungal infection  \n",
      "\n",
      "[5 rows x 133 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Training.csv')\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['itching', 'skin_rash', 'nodal_skin_eruptions', 'continuous_sneezing',\n",
      "       'shivering', 'chills', 'joint_pain', 'stomach_pain', 'acidity',\n",
      "       'ulcers_on_tongue',\n",
      "       ...\n",
      "       'blackheads', 'scurring', 'skin_peeling', 'silver_like_dusting',\n",
      "       'small_dents_in_nails', 'inflammatory_nails', 'blister',\n",
      "       'red_sore_around_nose', 'yellow_crust_ooze', 'prognosis'],\n",
      "      dtype='object', length=133)\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fungal infection' 'Allergy' 'GERD' 'Chronic cholestasis' 'Drug Reaction'\n",
      " 'Peptic ulcer diseae' 'AIDS' 'Diabetes ' 'Gastroenteritis'\n",
      " 'Bronchial Asthma' 'Hypertension ' 'Migraine' 'Cervical spondylosis'\n",
      " 'Paralysis (brain hemorrhage)' 'Jaundice' 'Malaria' 'Chicken pox'\n",
      " 'Dengue' 'Typhoid' 'hepatitis A' 'Hepatitis B' 'Hepatitis C'\n",
      " 'Hepatitis D' 'Hepatitis E' 'Alcoholic hepatitis' 'Tuberculosis'\n",
      " 'Common Cold' 'Pneumonia' 'Dimorphic hemmorhoids(piles)' 'Heart attack'\n",
      " 'Varicose veins' 'Hypothyroidism' 'Hyperthyroidism' 'Hypoglycemia'\n",
      " 'Osteoarthristis' 'Arthritis' '(vertigo) Paroymsal  Positional Vertigo'\n",
      " 'Acne' 'Urinary tract infection' 'Psoriasis' 'Impetigo']\n"
     ]
    }
   ],
   "source": [
    "print(data['prognosis'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.2-cp310-cp310-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.12.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (57.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/mohamedlotfy/Library/Python/3.10/lib/python/site-packages (from tensorflow) (4.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/mohamedlotfy/Library/Python/3.10/lib/python/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp310-cp310-macosx_12_0_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: rich in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from keras>=3.0.0->tensorflow) (13.6.0)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m963.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from rich->keras>=3.0.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.16.2-cp310-cp310-macosx_10_15_x86_64.whl (259.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.67.1-cp310-cp310-macosx_12_0_universal2.whl (10.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp310-cp310-macosx_10_9_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp310-cp310-macosx_10_9_universal2.whl (543 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.1/543.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, optree, opt-einsum, ml-dtypes, markdown, h5py, grpcio, google-pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 0.16.1\n",
      "    Uninstalling Werkzeug-0.16.1:\n",
      "\u001b[31mERROR: Could not install packages due to an OSError: Cannot move the non-empty directory '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/Werkzeug-0.16.1.dist-info/': Lacking write permission to '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/Werkzeug-0.16.1.dist-info/'.\n",
      "\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('Training.csv')\n",
    "X = data.drop('prognosis', axis=1)\n",
    "y = data['prognosis']\n",
    "\n",
    "# Encode the target labels if necessary\n",
    "y_encoded = pd.factorize(y)[0]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "SVC Accuracy: 100.00%\n",
      "SVC Confusion Matrix:\n",
      "[[19,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 24,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 26,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 22,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 24]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest Accuracy: 100.00%\n",
      "RandomForest Confusion Matrix:\n",
      "[[19,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 24,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 26,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 22,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 24]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Training GradientBoosting...\n",
      "GradientBoosting Accuracy: 100.00%\n",
      "GradientBoosting Confusion Matrix:\n",
      "[[19,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 24,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 26,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 22,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 24]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Training KNeighbors...\n",
      "KNeighbors Accuracy: 100.00%\n",
      "KNeighbors Confusion Matrix:\n",
      "[[19,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 24,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 26,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 22,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 24]]\n",
      "\n",
      "========================================\n",
      "\n",
      "Training MultinomialNB...\n",
      "MultinomialNB Accuracy: 100.00%\n",
      "MultinomialNB Confusion Matrix:\n",
      "[[19,  0,  0, ...,  0,  0,  0],\n",
      " [ 0, 24,  0, ...,  0,  0,  0],\n",
      " [ 0,  0, 28, ...,  0,  0,  0],\n",
      " ...,\n",
      " [ 0,  0,  0, ..., 26,  0,  0],\n",
      " [ 0,  0,  0, ...,  0, 22,  0],\n",
      " [ 0,  0,  0, ...,  0,  0, 24]]\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define the models to train\n",
    "models = {\n",
    "    'SVC': SVC(kernel='linear', random_state=42),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n",
    "    'MultinomialNB': MultinomialNB()\n",
    "}\n",
    "\n",
    "# Loop through models, train, test, and print results\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    print(f\"{model_name} Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(f\"{model_name} Confusion Matrix:\")\n",
    "    print(np.array2string(cm, separator=', '))\n",
    "\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(models['RandomForest'], 'random_forest_model.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
